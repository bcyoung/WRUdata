---
title: "WRU_squadscraping"
author: "BY"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
install.packages("rvest")
install.packages("dplyr")

# Load libraries
library(rvest)
library(dplyr)

```
Define the url and extract the html
```{r}
url <- "https://en.wikipedia.org/wiki/2008_Six_Nations_Championship_squads"

webpage <- read_html(url)
```

First, I need to inspect the web page structure to locate the table for the Wales squad. Wikipedia tables often have class names or other identifiers. Weâ€™ll look for a table under the Wales section.

Extract all tables from the webpage

```{r}
tables <- html_nodes(webpage, "table")
```

Wales table
```{r}
WRUSquad_2008 <- html_table(tables[[6]], fill = TRUE)
```
Convert the list to a data frame

```{r}
df_WRUSquad_2008 <- as.data.frame(WRUSquad_2008)
```

Clean up the column names and data as necessary. This step will vary based on the specific structure of the table
Remove empty rows
```{r}
colnames(df_WRUSquad_2008) <- c("Player", "Position", "DOB", "Caps", "Club")
df_WRUSquad_2008 <- df_WRUSquad_2008 %>% 
  filter(Player != "")  
```

Display cleaned table
```{r}
print(df_WRUSquad_2008)
write.csv(df_WRUSquad_2008, file = "df_WRUSquad_2008.csv")
```

Repeat for other years
2009
```{r}
url <- "https://en.wikipedia.org/wiki/2009_Six_Nations_Championship_squads"

webpage <- read_html(url)
tables <- html_nodes(webpage, "table")

WRUSquad_2009 <- html_table(tables[[6]], fill = TRUE)
df_WRUSquad_2009 <- as.data.frame(WRUSquad_2009)
colnames(df_WRUSquad_2009) <- c("Player", "Position", "DOB", "Caps", "Club")
df_WRUSquad_2009 <- df_WRUSquad_2009 %>% 
  filter(Player != "")  

print(df_WRUSquad_2009)
write.csv(df_WRUSquad_2009, file = "df_WRUSquad_2009.csv")
```
